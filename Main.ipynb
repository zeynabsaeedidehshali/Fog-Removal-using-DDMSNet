{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "paper: Deep Dense Multi-scale Network for Snow Removal Using Semantic and Geometric Priors\n",
    "file: model.py\n",
    "about: Main entrance for DDMSNet\n",
    "date: 03/07/20\n",
    "\"\"\"\n",
    "# --- Imports --- #\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from train_data import TrainData\n",
    "from val_data import ValData, Snow100KValData\n",
    "from model import GridDehazeNet, MultiScaleGridModel, DesnowModelDepth, DesnowModelSemantic, DesnowModelMulti, GridDehazeNetSingle, ImageMultiScaleNet, DDMSNet\n",
    "from utils import to_psnr, print_log, validation, adjust_learning_rate\n",
    "from torchvision.models import vgg16\n",
    "from perceptual import LossNetwork\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddfbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05be7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dill\n",
    "import numpy as np\n",
    "from VNL_depth.lib.utils.logging import setup_logging\n",
    "import torchvision.transforms as transforms\n",
    "from VNL_depth.lib.models.metric_depth_model import MetricDepthModel\n",
    "from VNL_depth.lib.core.config import merge_cfg_from_file, print_configs\n",
    "from VNL_depth.lib.models.image_transfer import bins_to_depth\n",
    "from collections import OrderedDict\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import sys\n",
    "from torch.backends import cudnn\n",
    "import semantic_seg.network\n",
    "from semantic_seg.datasets import cityscapes, kitti\n",
    "# We only need BN layer\n",
    "from semantic_seg.config import infer_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parse hyper-parameters  --- #\n",
    "parser = argparse.ArgumentParser(description='Hyper-parameters for DDMSNet')\n",
    "parser.add_argument('-learning_rate', help='Set the learning rate', default=0.0005, type=float)\n",
    "parser.add_argument('-crop_size', help='Set the crop_size', default=[240, 240], nargs='+', type=int)\n",
    "parser.add_argument('-train_batch_size', help='Set the training batch size', default=3, type=int)\n",
    "parser.add_argument('-network_height', help='Set the backbone height (row)', default=3, type=int)\n",
    "parser.add_argument('-network_width', help='Set the backbone width (column)', default=6, type=int)\n",
    "parser.add_argument('-num_dense_layer', help='Set the number of dense layer in RDB', default=4, type=int)\n",
    "parser.add_argument('-growth_rate', help='Set the growth rate in RDB', default=16, type=int)\n",
    "parser.add_argument('-lambda_loss', help='Set the lambda in loss function', default=0.04, type=float)\n",
    "parser.add_argument('-val_batch_size', help='Set the validation/test batch size', default=1, type=int)\n",
    "parser.add_argument('-levels', help='Set multi-scale levels of the backbone', default=3, type=int)\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = args.learning_rate\n",
    "crop_size = args.crop_size\n",
    "train_batch_size = args.train_batch_size\n",
    "network_height = args.network_height\n",
    "network_width = args.network_width\n",
    "num_dense_layer = args.num_dense_layer\n",
    "growth_rate = args.growth_rate\n",
    "lambda_loss = args.lambda_loss\n",
    "val_batch_size = args.val_batch_size\n",
    "category = \"args.category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Hyper-parameters for training ---')\n",
    "print('learning_rate: {}\\ncrop_size: {}\\ntrain_batch_size: {}\\nval_batch_size: {}\\nnetwork_height: {}\\nnetwork_width: {}\\n'\n",
    "      'num_dense_layer: {}\\ngrowth_rate: {}\\nlambda_loss: {}\\ncategory: {}'.format(learning_rate, crop_size,\n",
    "      train_batch_size, val_batch_size, network_height, network_width, num_dense_layer, growth_rate, lambda_loss, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91232213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set category-specific hyper-parameters  --- #\n",
    "\n",
    "num_epochs = 30\n",
    "train_data_dir = 'train/'\n",
    "val_data_dir = 'val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gpu device --- #\n",
    "device_ids = [Id for Id in range(torch.cuda.device_count())]\n",
    "#print(device_ids)\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cuda')\n",
    "print(\"************\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define depth network --- #\n",
    "\n",
    "depth_extract_net = MetricDepthModel()\n",
    "depth_extract_net = depth_extract_net.to(device)\n",
    "depth_extract_net = nn.DataParallel(depth_extract_net, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf45cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- load depth model --- #\n",
    "try:\n",
    "    ckpt_depth_path = 'kitti_eigen.pth'\n",
    "    ckpt = torch.load(ckpt_depth_path, map_location=lambda storage, loc: storage, pickle_module=dill)\n",
    "    state_dict = ckpt['model_state_dict']\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = 'module.' + k  # add `module.`\n",
    "        new_state_dict[name] = v\n",
    "    depth_extract_net.load_state_dict(new_state_dict)\n",
    "    #depth_extract_net.load_state_dict(ckpt['model_state_dict'])\n",
    "    print('--- depth net weight loaded ---')\n",
    "except:\n",
    "    print('--- no depth weight loaded ---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- frozen all params of depth network --- #\n",
    "for param in depth_extract_net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f12ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define semantic network --- #\n",
    "\n",
    "infer_cfg(train_mode=False)\n",
    "arch = 'semantic_seg.network.deepv3.DeepWV3Plus'\n",
    "dataset_cls = kitti\n",
    "semantic_extract_net = semantic_seg.network.get_net(arch, dataset_cls, criterion=None)\n",
    "semantic_extract_net = semantic_extract_net.to(device)\n",
    "#semantic_extract_net = nn.DataParallel(semantic_extract_net, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load semantic model --- #\n",
    "\n",
    "ckpt_semantic_path = 'kitti_best.pth'\n",
    "ckpt = torch.load(ckpt_semantic_path, map_location=lambda storage, loc: storage, pickle_module=dill)\n",
    "state_dict = ckpt['state_dict']\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    #name = 'module.' + k  # add `module.`\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "semantic_extract_net.load_state_dict(new_state_dict)\n",
    "print('--- semantic net weight loaded ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- frozen all params of depth network --- #\n",
    "for param in semantic_extract_net.parameters():\n",
    "    param.requires_grad = False\n",
    "semantic_extract_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the backbone network --- #\n",
    "net = DDMSNet(depth_extract_model=depth_extract_net, semantic_extract_model=semantic_extract_net, height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
    "\n",
    "net = net.to(device)\n",
    "net = nn.DataParallel(net, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the network weight --- #\n",
    "try:\n",
    "    ckpt_backbone_path = 'cityscapes_DDMSNet'\n",
    "    ckpt = torch.load(ckpt_backbone_path)\n",
    "    net.load_state_dict(ckpt['net'])\n",
    "    epoch = ckpt['epoch'] + 1\n",
    "    print('--- backbone weight loaded ---')\n",
    "except:\n",
    "    epoch = 0\n",
    "    print('--- no weight loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build optimizer --- #\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the perceptual loss network --- #\n",
    "vgg_model = vgg16(pretrained=True).features[:16]\n",
    "vgg_model = vgg_model.to(device)\n",
    "for param in vgg_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896df41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_network = LossNetwork(vgg_model)\n",
    "loss_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calculate all trainable parameters in network --- #\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"Total_params: {}\".format(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load training data and validation/test data --- #\n",
    "train_data_loader = DataLoader(TrainData(crop_size, train_data_dir), batch_size=train_batch_size, shuffle=True, num_workers=24, drop_last=True)\n",
    "val_data_loader = DataLoader(ValData(val_data_dir), batch_size=1, shuffle=False, num_workers=24, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(net.__class__)\n",
    "while epoch < 30:\n",
    "    psnr_list = []\n",
    "    \n",
    "    adjust_learning_rate(optimizer, epoch, category=category)\n",
    "\n",
    "    for batch_id, train_data in enumerate(train_data_loader):\n",
    "        #print(\"*******\")\n",
    "        snow, gt = train_data\n",
    "        snow = snow.to(device)\n",
    "        gt = gt.to(device)\n",
    "\n",
    "        # --- Zero the parameter gradients --- #\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # --- Forward + Backward + Optimize --- #\n",
    "        net.train()\n",
    "        desnow = net(snow)\n",
    "\n",
    "        # --- Calculate Total loss --- #\n",
    "        total_loss = 0\n",
    "        loss = []\n",
    "        smooth_loss = F.smooth_l1_loss(desnow, gt)\n",
    "        perceptual_loss = loss_network(desnow, gt)\n",
    "        total_loss = smooth_loss + lambda_loss * perceptual_loss    \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # --- To calculate average PSNR --- #\n",
    "        psnr_list.extend(to_psnr(desnow, gt))\n",
    "\n",
    "        if not (batch_id % 100):\n",
    "            print('Epoch: {0}, Iteration: {1}'.format(epoch, batch_id))\n",
    "            print('total_loss = {0}'.format(total_loss))\n",
    "\n",
    "    train_psnr = sum(psnr_list) / len(psnr_list)\n",
    "        #psnr_list = []\n",
    "    net.eval()\n",
    "    val_psnr, val_ssim = validation(net, val_data_loader, device, category)\n",
    "    one_epoch_time = time.time() - start_time\n",
    "    print_log(epoch+1, num_epochs, one_epoch_time, train_psnr, val_psnr, val_ssim, category)\n",
    "    # start_time = time.time()\n",
    "    \n",
    "    epoch += 1  \n",
    "    print(epoch)\n",
    "    state = {'net':net.state_dict(), 'epoch':epoch}\n",
    "    torch.save(state, 'checkpoints/foggy_{}'.format(epoch))\n",
    "\n",
    "    #--- Use the evaluation model in testing --- #\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2e22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
